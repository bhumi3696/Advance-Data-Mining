barplot(table(y), main = "Distribution of winning team", ylab="Frequency")
set.seed(1337)
index <- sample(1:length(y), length(y) * .25, replace=FALSE)
testing <- y[index]
perishModel <- rep("No", length(testing))
coinModel <- round(runif(length(testing), min=0, max=1))
coinModel <- factor(coinModel, levels = c(0,1), labels = c("No", "Yes"))
perishModel <- factor(perishModel, levels = c("No", "Yes"), labels = c("No", "Yes"))
table(testing, perishModel)
table(testing, coinModel)
(coinAccuracy <- 1 - mean(coinModel != testing))
(perishAccuracy <- 1 - mean(perishModel != testing))
perish <- c()
coin <- c()
for (i in 1:1000) {
index <- sample(1:length(y), length(y) * .25, replace=FALSE)
testing <- y[index]
coinModel <- round(runif(length(testing), min=0, max=1))
coinModel <- factor(coinModel, levels = c(0,1), labels = c("No", "Yes"))
coin[i] <- 1 - mean(coinModel != testing)
perish[i] <- 1 - mean(perishModel != testing)
}
results <- data.frame(coin, perish)
names(results) <- c("Coin Toss Accuracy", "Everyone Perishes Accuracy")
summary(results)
library(ggplot2)
library(reshape)
ggplot(melt(results), mapping = aes (fill = variable, x = value)) + geom_density (alpha = .5)
boxplot(results)
df <- win[, c("Win", "TossWin")]
df$Win <- factor(df$Win, levels = c(0,1), labels = c("No", "Yes"))
index <- sample(1:dim(df)[1], dim(df)[1] * .75, replace=FALSE)
training <- df[index, ]
testing <- df[-index, ]
table(training$Win, training$TossWin)
predictWin <- function(data) {
model <- rep("No", dim(data)[1])
model[data$TossWin == 1] <- "Yes"
return(model)
}
win <- c()
for (i in 1:1000) {
index <- sample(1:dim(df)[1], dim(df)[1] * .75, replace=FALSE)
testing <- df[-index, ]
winModel <- predictWin(testing)
win[i] <- 1 - mean(winModel != testing$Win)
}
results$`Winning Accuracy` <- win
names(results) <- c("Coin", "All Perish", "toss winning")
boxplot(results)
library(gmodels)
CrossTable(testing$Win, winModel)
CrossTable(testing$Win, winModel, prop.chisq = F, prop.c = F, prop.r = F)
library(caret)
library(e1071)
confusionMatrix(table(testing$Win,winModel))
winModel
testing$Win
model[data$TossWin == '1'] <- "Yes"
predictWin <- function(data) {
model <- rep("No", dim(data)[1])
model[data$TossWin == '1'] <- "Yes"
return(model)
}
TossWin
win <- c()
testing
predictWin <- function(data) {
model <- rep("No", dim(data)[1])
model[data$TossWin == '1'] <- "Yes"
return(model)
}
win <- c()
for (i in 1:1000) {
index <- sample(1:dim(df)[1], dim(df)[1] * .75, replace=FALSE)
testing <- df[-index, ]
winModel <- predictWin(testing)
win[i] <- 1 - mean(winModel != testing$Win)
}
results$`Winning Accuracy` <- win
names(results) <- c("Coin", "All Perish", "toss winning")
boxplot(results)
testing
winModel
library(gmodels)
CrossTable(testing$Win, winModel)
CrossTable(testing$Win, winModel, prop.chisq = F, prop.c = F, prop.r = F)
library(caret)
library(e1071)
confusionMatrix(table(testing$Win,winModel))
library(dplyr)
#toss winning
win = read.csv("D:/SEM 2/ADM/project/IPL-ADM/IPL_ADM/Match_Impact_Teams.csv")
y <- win$Win
table(y)
y <- factor(y, levels = c(0,1), labels = c("No", "Yes"))
table(y)
prop.table(table(y))
barplot(table(y), main = "Distribution of winning team", ylab="Frequency")
set.seed(1337)
index <- sample(1:length(y), length(y) * .25, replace=FALSE)
testing <- y[index]
perishModel <- rep("No", length(testing))
coinModel <- round(runif(length(testing), min=0, max=1))
coinModel <- factor(coinModel, levels = c(0,1), labels = c("No", "Yes"))
perishModel <- factor(perishModel, levels = c("No", "Yes"), labels = c("No", "Yes"))
table(testing, perishModel)
table(testing, coinModel)
(coinAccuracy <- 1 - mean(coinModel != testing))
(perishAccuracy <- 1 - mean(perishModel != testing))
perish <- c()
coin <- c()
for (i in 1:1000) {
index <- sample(1:length(y), length(y) * .25, replace=FALSE)
testing <- y[index]
coinModel <- round(runif(length(testing), min=0, max=1))
coinModel <- factor(coinModel, levels = c(0,1), labels = c("No", "Yes"))
coin[i] <- 1 - mean(coinModel != testing)
perish[i] <- 1 - mean(perishModel != testing)
}
results <- data.frame(coin, perish)
names(results) <- c("Coin Toss Accuracy", "Everyone Perishes Accuracy")
summary(results)
library(ggplot2)
library(reshape)
ggplot(melt(results), mapping = aes (fill = variable, x = value)) + geom_density (alpha = .5)
boxplot(results)
df <- win[, c("Win", "TossWin")]
df$Win <- factor(df$Win, levels = c(0,1), labels = c("No", "Yes"))
index <- sample(1:dim(df)[1], dim(df)[1] * .75, replace=FALSE)
training <- df[index, ]
testing <- df[-index, ]
table(training$Win, training$TossWin)
predictWin <- function(data) {
model <- rep("No", dim(data)[1])
model[data$TossWin == 1] <- "Yes"
return(model)
}
win <- c()
for (i in 1:1000) {
index <- sample(1:dim(df)[1], dim(df)[1] * .75, replace=FALSE)
testing <- df[-index, ]
winModel <- predictWin(testing)
win[i] <- 1 - mean(winModel != testing$Win)
}
results$`Winning Accuracy` <- win
names(results) <- c("Coin", "All Perish", "toss winning")
boxplot(results)
library(gmodels)
CrossTable(testing$Win, winModel)
CrossTable(testing$Win, winModel, prop.chisq = F, prop.c = F, prop.r = F)
library(caret)
library(e1071)
confusionMatrix(table(winModel, testing$Win))
install.packages("caret")
install.packages("caret")
confusionMatrix(table(winModel, testing$Win))
install.packages("e1071")
install.packages("gmodels")
library(dplyr)
#toss winning
win = read.csv("D:/SEM 2/ADM/project/IPL-ADM/IPL_ADM/Match_Impact_Teams.csv")
y <- win$Win
table(y)
y <- factor(y, levels = c(0,1), labels = c("No", "Yes"))
table(y)
prop.table(table(y))
barplot(table(y), main = "Distribution of winning team", ylab="Frequency")
set.seed(1337)
index <- sample(1:length(y), length(y) * .25, replace=FALSE)
testing <- y[index]
perishModel <- rep("No", length(testing))
coinModel <- round(runif(length(testing), min=0, max=1))
coinModel <- factor(coinModel, levels = c(0,1), labels = c("No", "Yes"))
perishModel <- factor(perishModel, levels = c("No", "Yes"), labels = c("No", "Yes"))
table(testing, perishModel)
table(testing, coinModel)
(coinAccuracy <- 1 - mean(coinModel != testing))
(perishAccuracy <- 1 - mean(perishModel != testing))
perish <- c()
coin <- c()
for (i in 1:1000) {
index <- sample(1:length(y), length(y) * .25, replace=FALSE)
testing <- y[index]
coinModel <- round(runif(length(testing), min=0, max=1))
coinModel <- factor(coinModel, levels = c(0,1), labels = c("No", "Yes"))
coin[i] <- 1 - mean(coinModel != testing)
perish[i] <- 1 - mean(perishModel != testing)
}
results <- data.frame(coin, perish)
names(results) <- c("Coin Toss Accuracy", "Everyone Perishes Accuracy")
summary(results)
library(ggplot2)
library(reshape)
ggplot(melt(results), mapping = aes (fill = variable, x = value)) + geom_density (alpha = .5)
boxplot(results)
df <- win[, c("Win", "TossWin")]
df$Win <- factor(df$Win, levels = c(0,1), labels = c("No", "Yes"))
index <- sample(1:dim(df)[1], dim(df)[1] * .75, replace=FALSE)
training <- df[index, ]
testing <- df[-index, ]
table(training$Win, training$TossWin)
predictWin <- function(data) {
model <- rep("No", dim(data)[1])
model[data$TossWin == 1] <- "Yes"
return(model)
}
win <- c()
for (i in 1:1000) {
index <- sample(1:dim(df)[1], dim(df)[1] * .75, replace=FALSE)
testing <- df[-index, ]
winModel <- predictWin(testing)
win[i] <- 1 - mean(winModel != testing$Win)
}
results$`Winning Accuracy` <- win
names(results) <- c("Coin", "All Perish", "toss winning")
boxplot(results)
library(gmodels)
CrossTable(testing$Win, winModel)
CrossTable(testing$Win, winModel, prop.chisq = F, prop.c = F, prop.r = F)
library(caret)
library(e1071)
confusionMatrix(table(winModel, testing$Win))
#Lab4(C5.0)
setwd("D:/SEM 2/ADM/practical/1")
titanicData <- read.csv("titanic.csv", header=T, na.strings=c(""), stringsAsFactors = T)
save(titanicData, file="titanticData.RData")
set.seed(1337)
#install.packages("C50")
library(C50)
cFifty <- C5.0(Survived ~., data=training, trials=10)
titanicData$Survived <- as.factor(titanicData$Survived)
titanicData = na.omit(titanicData)
str(titanicData)
#Task 1
library(C50)
library(caret)
index <- sample(1:dim(titanicData)[1], dim(titanicData)[1] * .75, replace=FALSE)
training <- titanicData[index, ]
testing <- titanicData[-index, ]
cFifty <- C5.0(Survived ~ PassengerId+Pclass+Sex+Age+SibSp+Parch+Fare+Cabin+Embarked, data=training)
c <- predict(cFifty, testing[, c(-4,-2,-9)])
caret::confusionMatrix(c, testing$Survived)
#winnowed
cFiftyWinnow <- C5.0(Survived ~ PassengerId+Pclass+Sex+Age+SibSp+Parch+Fare+Cabin+Embarked, data = training, control = C5.0Control(winnow = TRUE))
c <- predict(cFiftyWinnow, testing[, c(-4,-2,-9)])
caret::confusionMatrix(c, testing$Survived)
library(caret)
control <- trainControl(method="repeatedcv", number=10, repeats=5) #5 x 10-fold cv
metric <- "Kappa"
a <-train(Survived~., data=titanicData, method="C5.0", metric=metric, trControl=control)
#lab4(Decision Trees - beyond C50)
set.wd("D:/SEM 2/ADM/practical/1")
titanicData <- read.csv("titanic.csv", header=T, na.strings=c(""), stringsAsFactors = T)
save(titanicData, file="titanticData.RData")
set.seed(1337)
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
library(RColorBrewer)
index <- sample(1:dim(titanicData)[1], dim(titanicData)[1] * .75, replace=FALSE)
training <- titanicData[index, ]
testing <- titanicData[-index, ]
regressionTree <- rpart(Survived ~ PassengerId+Pclass+Sex+Age+Parch+Fare+Embarked, data=training, method="class")
tree <- rpart(Survived ~ PassengerId+Pclass+Fare+Embarked+Sex+Age+Parch, data=training, method="class")
plot(regressionTree)
text(regressionTree)
plot(tree)
text(tree)
summary(regressionTree)
library(rattle)
#install.packages("rattle")
fancyRpartPlot(regressionTree)
Prediction <- predict(regressionTree, training, type = "class")
confusionMatrix(table(Prediction, training$Survived))
#Clustering(lab 5)
library(ggfortify) #for plots
#Clustering(lab 5)
install.packages("ggfortify")
#Clustering(lab 5)
library(ggfortify) #for plots
df <- iris[c(1:4)] # removes the class label: feature 5
autoplot(prcomp(df, scale. = T, center = T), data = iris, colour = 'Species')
screeplot(prcomp(df, scale. = T, center = T), type="lines")
install.packages("factoextra")
library(factoextra)
install.packages("FactoMineR")
library(FactoMineR)
pca <- PCA(iris[, -5], scale.unit = T, ncp=3)
fviz_screeplot(pca, addlabels = TRUE)
library(factoextra)
pca <- PCA(iris[, -5], scale.unit = T, ncp=3)
fviz_pca_ind(pca, habillage = iris$Species, label="none", addEllipses = T)
#k-mean
table(iris$Species)
set.seed(1337)
myIris <- iris[, c(1:4)] #removing the dependent
myIris <- sapply(myIris, FUN=function(x) { scale(x, scale = T, center=T)})
res.1 <- kmeans(myIris, 3)
str(res.1)
df <- data.frame(cluster = res.1$cluster, species = iris$Species)
table (factor(df$cluster), df$species)
myIris <- iris[, c(1:4)] #removing the dependent
myIris <- sapply(myIris, FUN=function(x) { scale(x, scale = T, center=F)})
res.2 <- kmeans(myIris, 3)
df <- data.frame(cluster = res.2$cluster, species = iris$Species)
table (factor(df$cluster), df$species)
pca <- prcomp(iris[, c(1:4)], scale. = T, center = T)
res.3 <- kmeans(pca$x[, 1:2], 3)
df <- data.frame(cluster = res.3$cluster, species = iris$Species)
table (factor(df$cluster), df$species)
pca <- prcomp(iris[, c(1:4)], scale. = T, center = F)
res.4 <- kmeans(pca$x[, 1:2], 3)
df <- data.frame(cluster = res.4$cluster, species = iris$Species)
table (factor(df$cluster), df$species)
totss <- c(res.1[[3]], res.2[[3]], res.3[[3]], res.4[[3]])
tos.withinss <- c(res.1[[5]], res.2[[5]], res.3[[5]], res.4[[5]])
betweenss <- c(res.1[[6]], res.2[[6]], res.3[[6]], res.4[[6]])
performance <- data.frame(totss, tos.withinss, betweenss)
row.names(performance) <- c("w/o pca +c", "w/o pca", "w pca +c", "w pca")
performance
plot(iris[,c(1:4)], col=res.1$cluster)
plot(iris[,c(1:4)], col=res.4$cluster)
plot(iris[,c(1:4)], col=res.4$cluster)
plot(iris[,c(1:4)], col=res.1$cluster)
plot(iris[,c(1:4)], col=res.4$cluster)
library(clusterSim) #for the dbindex
install.packages("clusterSim")
library(clusterSim) #for the dbindex
library(cluster) #for the silhouette
results <- list()
tot.withinss <- c()
betweenss <- c()
dbindex <- c()
silhouettes <- c()
for (k in 2:10) {
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
dbindex[k] <- index.DB(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
}
par(mfrow=c(2,2))
plot(tot.withinss, xlab="k")
plot(betweenss, xlab="k")
plot(dbindex, xlab="k")
plot(silhouettes, xlab="k")
library(cluster) #for the silhouette
results <- list()
tot.withinss <- c()
betweenss <- c()
dbindex <- c()
silhouettes <- c()
for (k in 2:10) {
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
dbindex[k] <- index.DB(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
}
par(mfrow=c(2,2))
plot(tot.withinss, xlab="k")
dbindex[k] <- index.DB(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
index.DB <- c()
dbindex[k] <- index.DB(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
for (k in 2:10) {
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
dbindex[k] <- index.DB(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
}
s <- silhouette(results[[k]]$cluster, daisy(myIris))
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
dbindex[k] <- index.DB(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
dbindex[k] <- dbindex(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
dbindex <- c()
dbindex[k] <- dbindex(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
cluster <- c()
dbindex[k] <- dbindex(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
par(mfrow=c(2,2))
plot(tot.withinss, xlab="k")
plot(betweenss, xlab="k")
plot(dbindex, xlab="k")
for (k in 2:10) {
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
#dbindex[k] <- dbindex(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
}
par(mfrow=c(2,2))
plot(tot.withinss, xlab="k")
plot(betweenss, xlab="k")
plot(dbindex, xlab="k")
plot(silhouettes, xlab="k")
for (k in 2:10) {
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
dbindex[k] <- dbindex(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
}
par(mfrow=c(2,2))
library(cluster) #for the silhouette
results <- list()
tot.withinss <- c()
betweenss <- c()
dbindex <- c()
silhouettes <- c()
for (k in 2:10) {
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
dbindex[k] <- dbindex(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
}
par(mfrow=c(2,2))
plot(tot.withinss, xlab="k")
plot(tot.withinss, xlab="k")
plot(betweenss, xlab="k")
plot(dbindex, xlab="k")
for (k in 2:10) {
results[[k]] <- kmeans(myIris, k)
tot.withinss[k] <- results[[k]]$tot.withinss
betweenss[k] <- results[[k]]$betweenss
#dbindex[k] <- dbindex(myIris, results[[k]]$cluster, centrotypes="centroids")$DB
s <- silhouette(results[[k]]$cluster, daisy(myIris))
silhouettes[k] <- mean(s[,3])
}
par(mfrow=c(2,2))
plot(tot.withinss, xlab="k")
plot(betweenss, xlab="k")
plot(dbindex, xlab="k")
plot(silhouettes, xlab="k")
plot(silhouette(results[[3]]$cluster, daisy(myIris)))
install.packages("fpc")
library(fpc)
plotcluster(myIris, res.2$cluster)
res.2$centers #coords of centroids
centers <- res.2$centers[res.2$cluster, ] #vector of all centers for each point
distances <- sqrt(rowSums((myIris - centers)^2)) #Euclidean pair-wise distances
summary(distances)
sd(distances)
# pick n largest distances: boring!
outliers <- order(distances, decreasing=T)[1:5]
# pick those more than 2 standard deviations from the mean
outliers <- (distances > (mean(distances) + (2 * sd(distances))) |
distances < (mean(distances) - (2 * sd(distances))))
print(myIris[outliers,])
# plot clusters (choose 2 dimensions for ease of display)
plot(myIris[,c("Sepal.Length", "Sepal.Width")], pch="o", col=res.2$cluster, cex=0.3)
# plot cluster centers
points(res.2$centers[,c("Sepal.Length", "Sepal.Width")], col=1:3, pch=8, cex=1.5)
# plot outliers
points(myIris[outliers, c("Sepal.Length", "Sepal.Width")], pch="+", col=4, cex=1.5)
#Hierarchical Agglomerative
d <- dist(myIris, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward.D")
plot(fit) # display dendogram
groups <- cutree(fit, k=3) # cut tree into 3 clusters
# draw dendogram with red borders around the 3 clusters
rect.hclust(fit, k=3, border="red")
#Density based clustering
ds <- dbscan(myIris, eps=.25, MinPts=5)
table(ds$cluster, iris$Species)
plot(ds, myIris)
plotcluster(myIris, ds$cluster)
d <- dist(myIris)
for (i in lowerBound:upperBound) {
ds <- dbscan(myIris, eps=i/100, MinPts = 5)
results[[i]] <- cluster.stats(d, ds$cluster)
results[[i]]$eps <- i/100
}
#prune the NULLS
results[sapply(results, is.null)] <- NULL
#pick what you want to plot, e.g. average silhouette width
avg.silwidth <- lapply(results, FUN = function(x) {
return (x$avg.silwidth)
})
eps <- lapply(results, FUN = function(x) {
return (x$eps)
})
plot(y=avg.silwidth, x=eps, xlab="eps")
install.packages("dbscan")
library(dbscan)
db <- dbscan(myIris, 0.4, 5)
hullplot(myIris, db$cluster)
#Model Based Clustering
library(mclust)
install.packages("mclust")
install.packages("mclust")
fit <- Mclust(myIris)
plot(fit, what = "classification") # plot results
summary(fit)
fit$classification
#Support Vector Machines(lab 7)
mnist <- read.csv("MNISTTrain.csv", header=T)
